{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project CS209b\n",
    "## Conditional Autoregression Flu - May 5\n",
    "### Benjamin Levy, Will Fried, Dimitris Vamvourellis & Matthieu Meeus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Alabama</th>\n",
       "      <th>Alaska</th>\n",
       "      <th>Arizona</th>\n",
       "      <th>Arkansas</th>\n",
       "      <th>California</th>\n",
       "      <th>Colorado</th>\n",
       "      <th>Connecticut</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>District of Columbia</th>\n",
       "      <th>...</th>\n",
       "      <th>Tennessee</th>\n",
       "      <th>Texas</th>\n",
       "      <th>Utah</th>\n",
       "      <th>Vermont</th>\n",
       "      <th>Virgin Islands</th>\n",
       "      <th>Virginia</th>\n",
       "      <th>Washington</th>\n",
       "      <th>West Virginia</th>\n",
       "      <th>Wisconsin</th>\n",
       "      <th>Wyoming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-40</td>\n",
       "      <td>2.13477</td>\n",
       "      <td>0.875146</td>\n",
       "      <td>0.674721</td>\n",
       "      <td>0.696056</td>\n",
       "      <td>1.95412</td>\n",
       "      <td>0.660684</td>\n",
       "      <td>0.078309</td>\n",
       "      <td>0.100125</td>\n",
       "      <td>2.80877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274655</td>\n",
       "      <td>2.06514</td>\n",
       "      <td>0.747696</td>\n",
       "      <td>1.47641</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.14343</td>\n",
       "      <td>0.510041</td>\n",
       "      <td>1.59741</td>\n",
       "      <td>0.465022</td>\n",
       "      <td>0.632911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-41</td>\n",
       "      <td>2.05999</td>\n",
       "      <td>1.128270</td>\n",
       "      <td>0.749939</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>2.15266</td>\n",
       "      <td>0.628621</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.368550</td>\n",
       "      <td>2.89079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499492</td>\n",
       "      <td>2.09394</td>\n",
       "      <td>0.410939</td>\n",
       "      <td>1.35777</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.23653</td>\n",
       "      <td>1.040070</td>\n",
       "      <td>1.58968</td>\n",
       "      <td>0.581832</td>\n",
       "      <td>0.440621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-42</td>\n",
       "      <td>1.94224</td>\n",
       "      <td>0.586042</td>\n",
       "      <td>0.953365</td>\n",
       "      <td>0.514217</td>\n",
       "      <td>2.24173</td>\n",
       "      <td>0.804020</td>\n",
       "      <td>0.374158</td>\n",
       "      <td>0.337025</td>\n",
       "      <td>2.41042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499550</td>\n",
       "      <td>2.10072</td>\n",
       "      <td>0.440583</td>\n",
       "      <td>1.48221</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.22545</td>\n",
       "      <td>0.904393</td>\n",
       "      <td>1.52672</td>\n",
       "      <td>1.188220</td>\n",
       "      <td>0.441798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-43</td>\n",
       "      <td>2.27650</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.888804</td>\n",
       "      <td>0.413650</td>\n",
       "      <td>1.91748</td>\n",
       "      <td>0.909658</td>\n",
       "      <td>0.333542</td>\n",
       "      <td>0.460494</td>\n",
       "      <td>3.11632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401638</td>\n",
       "      <td>2.20655</td>\n",
       "      <td>0.755957</td>\n",
       "      <td>1.44393</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.26902</td>\n",
       "      <td>0.955110</td>\n",
       "      <td>1.81171</td>\n",
       "      <td>1.010490</td>\n",
       "      <td>0.490305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-44</td>\n",
       "      <td>2.83371</td>\n",
       "      <td>0.683851</td>\n",
       "      <td>1.185730</td>\n",
       "      <td>1.090280</td>\n",
       "      <td>2.52326</td>\n",
       "      <td>0.971705</td>\n",
       "      <td>0.396743</td>\n",
       "      <td>0.222332</td>\n",
       "      <td>2.99118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528096</td>\n",
       "      <td>2.36381</td>\n",
       "      <td>0.651859</td>\n",
       "      <td>1.25276</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.26547</td>\n",
       "      <td>0.786370</td>\n",
       "      <td>1.83986</td>\n",
       "      <td>1.096490</td>\n",
       "      <td>0.566636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time  Alabama    Alaska   Arizona  Arkansas  California  Colorado  \\\n",
       "0  2010-40  2.13477  0.875146  0.674721  0.696056     1.95412  0.660684   \n",
       "1  2010-41  2.05999  1.128270  0.749939  0.674157     2.15266  0.628621   \n",
       "2  2010-42  1.94224  0.586042  0.953365  0.514217     2.24173  0.804020   \n",
       "3  2010-43  2.27650  0.967742  0.888804  0.413650     1.91748  0.909658   \n",
       "4  2010-44  2.83371  0.683851  1.185730  1.090280     2.52326  0.971705   \n",
       "\n",
       "   Connecticut  Delaware  District of Columbia  ...  Tennessee    Texas  \\\n",
       "0     0.078309  0.100125               2.80877  ...   0.274655  2.06514   \n",
       "1     0.238095  0.368550               2.89079  ...   0.499492  2.09394   \n",
       "2     0.374158  0.337025               2.41042  ...   0.499550  2.10072   \n",
       "3     0.333542  0.460494               3.11632  ...   0.401638  2.20655   \n",
       "4     0.396743  0.222332               2.99118  ...   0.528096  2.36381   \n",
       "\n",
       "       Utah  Vermont  Virgin Islands  Virginia  Washington  West Virginia  \\\n",
       "0  0.747696  1.47641          0.0001   1.14343    0.510041        1.59741   \n",
       "1  0.410939  1.35777          0.0001   1.23653    1.040070        1.58968   \n",
       "2  0.440583  1.48221          0.0001   1.22545    0.904393        1.52672   \n",
       "3  0.755957  1.44393          0.0001   1.26902    0.955110        1.81171   \n",
       "4  0.651859  1.25276          0.0001   1.26547    0.786370        1.83986   \n",
       "\n",
       "   Wisconsin   Wyoming  \n",
       "0   0.465022  0.632911  \n",
       "1   0.581832  0.440621  \n",
       "2   1.188220  0.441798  \n",
       "3   1.010490  0.490305  \n",
       "4   1.096490  0.566636  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paths to data\n",
    "PATH_TO_FLU = 'flu_ground_truth/'\n",
    "PATH_TO_STATESTATS = 'state_stats.csv'\n",
    "\n",
    "# open all flu csv files and save them in one dataframe\n",
    "flu_data = pd.DataFrame()\n",
    "for filename in os.listdir(PATH_TO_FLU ):\n",
    "    if flu_data.empty:\n",
    "        state = filename[13:-4]\n",
    "        flu_data = pd.read_csv(PATH_TO_FLU  + filename)\n",
    "        flu_data.rename(columns={\"wili\": state}, inplace = True)\n",
    "    else:\n",
    "        state = filename[13:-4]\n",
    "        state_data = pd.read_csv(PATH_TO_FLU + filename)\n",
    "        flu_data[state] = state_data['wili'] \n",
    "\n",
    "flu_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>density_metric</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>is_coastal</th>\n",
       "      <th>airport_arrivals</th>\n",
       "      <th>Children 0-18</th>\n",
       "      <th>Adults 19-25</th>\n",
       "      <th>Adults 26-34</th>\n",
       "      <th>Adults 35-54</th>\n",
       "      <th>Adults 55-64</th>\n",
       "      <th>65+</th>\n",
       "      <th>...</th>\n",
       "      <th>ID_is_neighbor</th>\n",
       "      <th>ME_is_neighbor</th>\n",
       "      <th>MS_is_neighbor</th>\n",
       "      <th>VT_is_neighbor</th>\n",
       "      <th>SD_is_neighbor</th>\n",
       "      <th>ND_is_neighbor</th>\n",
       "      <th>MT_is_neighbor</th>\n",
       "      <th>WY_is_neighbor</th>\n",
       "      <th>overall_vacc_rate</th>\n",
       "      <th>child_vacc_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NY</th>\n",
       "      <td>10711.4</td>\n",
       "      <td>40.705626</td>\n",
       "      <td>1</td>\n",
       "      <td>2.625045</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.7</td>\n",
       "      <td>69.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>2789.6</td>\n",
       "      <td>40.143006</td>\n",
       "      <td>1</td>\n",
       "      <td>2.333070</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.4</td>\n",
       "      <td>72.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>1957.6</td>\n",
       "      <td>40.994593</td>\n",
       "      <td>1</td>\n",
       "      <td>1.621257</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>1761.9</td>\n",
       "      <td>39.739318</td>\n",
       "      <td>0</td>\n",
       "      <td>4.102417</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>60.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MD</th>\n",
       "      <td>1737.6</td>\n",
       "      <td>38.806352</td>\n",
       "      <td>1</td>\n",
       "      <td>2.316047</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.9</td>\n",
       "      <td>74.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    density_metric   Latitude  is_coastal  airport_arrivals  Children 0-18  \\\n",
       "NY         10711.4  40.705626           1          2.625045           0.22   \n",
       "NJ          2789.6  40.143006           1          2.333070           0.23   \n",
       "PA          1957.6  40.994593           1          1.621257           0.22   \n",
       "IL          1761.9  39.739318           0          4.102417           0.24   \n",
       "MD          1737.6  38.806352           1          2.316047           0.23   \n",
       "\n",
       "    Adults 19-25  Adults 26-34  Adults 35-54  Adults 55-64   65+  ...  \\\n",
       "NY          0.09          0.13          0.26          0.14  0.16  ...   \n",
       "NJ          0.08          0.11          0.27          0.14  0.16  ...   \n",
       "PA          0.08          0.12          0.25          0.14  0.18  ...   \n",
       "IL          0.09          0.12          0.26          0.13  0.15  ...   \n",
       "MD          0.08          0.12          0.27          0.14  0.15  ...   \n",
       "\n",
       "    ID_is_neighbor  ME_is_neighbor  MS_is_neighbor  VT_is_neighbor  \\\n",
       "NY               0               0               0               1   \n",
       "NJ               0               0               0               0   \n",
       "PA               0               0               0               0   \n",
       "IL               0               0               0               0   \n",
       "MD               0               0               0               0   \n",
       "\n",
       "    SD_is_neighbor  ND_is_neighbor  MT_is_neighbor  WY_is_neighbor  \\\n",
       "NY               0               0               0               0   \n",
       "NJ               0               0               0               0   \n",
       "PA               0               0               0               0   \n",
       "IL               0               0               0               0   \n",
       "MD               0               0               0               0   \n",
       "\n",
       "    overall_vacc_rate  child_vacc_rate  \n",
       "NY               81.7             69.6  \n",
       "NJ               79.4             72.8  \n",
       "PA               82.5             69.7  \n",
       "IL               83.0             60.1  \n",
       "MD               81.9             74.5  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_data = pd.read_csv(PATH_TO_STATESTATS)\n",
    "state_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District of Columbia\n",
      "New York City\n",
      "Puerto Rico\n",
      "Virgin Islands\n",
      "------------\n",
      "------------\n",
      "AK\n",
      "HI\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary of state names to 2 letter abbreviations and back\n",
    "state_name2abbrev = {\n",
    "    'Alabama':'AL','Alaska':'AK','Arizona':'AZ','Arkansas':'AR','California':'CA', \n",
    "    'Colorado':'CO','Connecticut':'CT','Delaware':'DE','Florida':'FL','Georgia':'GA',\n",
    "    'Hawaii':'HI','Idaho':'ID','Illinois':'IL','Indiana':'IN','Iowa':'IA','Kansas':'KS',\n",
    "    'Kentucky':'KY','Louisiana':'LA','Maine':'ME','Maryland':'MD','Massachusetts':'MA',\n",
    "    'Michigan':'MI','Minnesota':'MN','Mississippi':'MS','Missouri':'MO','Montana':'MT',\n",
    "    'Nebraska':'NE','Nevada':'NV','New Hampshire':'NH','New Jersey':'NJ','New Mexico':'NM',\n",
    "    'New York':'NY','North Carolina':'NC','North Dakota':'ND','Ohio':'OH','Oklahoma':'OK',\n",
    "    'Oregon':'OR','Pennsylvania':'PA','Rhode Island':'RI','South Carolina':'SC',\n",
    "    'South Dakota':'SD','Tennessee':'TN','Texas':'TX','Utah':'UT','Vermont':'VT',\n",
    "    'Virginia':'VA','Washington':'WA','West Virginia':'WV','Wisconsin':'WI','Wyoming':'WY'\n",
    "}\n",
    "\n",
    "state_abbrev2name = {state_name2abbrev[name]:name for name in state_name2abbrev.keys()}\n",
    "\n",
    "for state in flu_data.columns:\n",
    "    if state not in state_name2abbrev.keys() and state != 'time':\n",
    "        print(state)\n",
    "print('------------')\n",
    "for state in state_data.index.values:\n",
    "    if state not in state_name2abbrev.values():\n",
    "        print(state)\n",
    "print('------------')\n",
    "for state in state_name2abbrev.values():\n",
    "    if state not in state_data.index.values:\n",
    "        print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conditional Autoregression: Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 General CAR\n",
    "\n",
    "We will first discuss the conditional autoregressive (CAR) model in general. It is widely used to model the spatial variation of the response variable $y_i$, where it is assumed that the probability of values estimated for a variable $z_i$ are conditional on neighboring values $z_j$. As such, it is a natural way to study the spatial relations present in specific data. It is thus potentially interesting to apply a CAR model to our geographically spread data on the flu. \n",
    "\n",
    "Consider a general Spatial Regression Model (SAR) to start with:\n",
    "\n",
    "$$y_i = X_i\\beta + z_i + \\epsilon_i$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $y_i$ is the response variable at node i, \n",
    "- $X_i$ the predictor variables measured at the same node as $y_i$, \n",
    "- $\\beta$ the regression coefficients,\n",
    "- $z_i$ a latent spatial random error $z_i \\sim N(0, \\Sigma_i)$,\n",
    "- $\\epsilon_i$ an independent error $\\epsilon_i \\sim N(0, \\sigma_{\\epsilon_i}^2)$\n",
    "\n",
    "In the Conditional AR model, the $z_i$ variable depends on the neighbouring values $z_j$ for $i \\neq j$:\n",
    "\n",
    "$$z_i | z_j, i \\neq j \\sim N(\\sum_{j \\neq i} c_{ij} z_j, m_{ii})$$\n",
    "\n",
    "Where $c_{ii} = 0$. As such, there are three main contributions to the response variable $y_i$: a regression of locally measured predictors, a conditional spatial term and a random error that is specific to the location. The matrix $C$ is often developed as $\\rho W$ where $W$ is the 'neighborhood matrix' and $\\rho$ an autocorelation factor. \n",
    "\n",
    "Reference to: https://eprints.qut.edu.au/115891/1/115891.pdf\n",
    "\n",
    "#### 2.2 CAR applied to state-dependent flu\n",
    "\n",
    "We will now try to embed the idea of CAR in our time series model. How I see it at this point:\n",
    "\n",
    "$$Y_{ti} = \\beta X_i + z_i + \\epsilon_i$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $Y_{ti}$ is the Wili in state i at time t. We still want to predict the response variable over time at a specific location, so this remains the response variable. \n",
    "- $X_i$ is a vector containing all the 'local' predictors. In the case of a AR time series model, this will contain the N previous Wili observations in time in state i.\n",
    "- $\\beta$ is a vector containing the local AR time-lag-regression coefficients. \n",
    "- $z_i$ is the latent spatial random error, which will be conditional on the neighbouring states, where neighbour still needs to be defined. \n",
    "- $\\epsilon_i$ an independent error $\\epsilon_i \\sim N(0, \\sigma_{\\epsilon_i}^2)$\n",
    "\n",
    "Now some more design decisions need to be made. \n",
    "\n",
    "First, distribution of the data? What would be reasonable? \n",
    "\n",
    "Next, we need to decide whether $\\beta$ will be state-specific or not. This comes down to the choice of sampling $\\beta_i$ from a normal distribution for each state separately $\\beta_i \\sim N(0, \\sigma^2)$ with $\\frac{1}{\\sigma^2} \\sim Gamma(0.1, 0.1)$ or considering one vector $\\beta$ for all states $\\beta_i \\sim N(0, \\sigma^2)$. I would argue that we want this to be state-independent as we hope to account for the state differences/similarities in the $z_i$.\n",
    "\n",
    "Second, we need to dive into the specifics of $z_i$. Recall:\n",
    "\n",
    "$$z_i | z_j, i \\neq j \\sim N(\\sum_{j \\neq i} c_{ij} z_j, m_{ii})$$\n",
    "\n",
    "And following standard practice, we can define the matrix $C = \\rho W$. Now it comes down to come up with a reasonable value for the correlation variable $\\rho$ and the construction of neighbor matrix $W$. \n",
    "\n",
    "One option is to start with the actual neighboring values (0 or 1) and a constant correlation variable. Another would be to come up with a W that incorporates (a clever selection of) the features we have. For instance a weighted combination of relative difference in population density and temperature. \n",
    "\n",
    "Question: what is the advantage/goal with this? Predicting using mean of posterior distributions? Or trying to understand the distributions for z? \n",
    "\n",
    "Another would be to model $c_{ij}$ based on all the features we have, in a similar fashion as Will's model:\n",
    "\n",
    "$$c_{ij} = \\beta_0 + \\beta_1I_{neighbor} + \\beta_2|density_i - density_j| \\ + \\beta_3*commute_{ij} \\ + ... + \\ \\beta_k|summer\\_temp_i - summer\\_temp_j|*I(season = summer)$$\n",
    "\n",
    "This would enable us to get an understanding of the feature importance. Or does this get too complicated? \n",
    "\n",
    "#### 2.3 Final model decision\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Coding it up\n",
    "\n",
    "Nice resource: https://docs.pymc.io/notebooks/PyMC3_tips_and_heuristic.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "from theano import shared, scan\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "from pymc3.distributions import continuous\n",
    "from pymc3.distributions import distribution\n",
    "floatX = \"float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAR(distribution.Continuous):\n",
    "    \"\"\"\n",
    "    Conditional Autoregressive (CAR) distribution\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : list of adjacency information\n",
    "    w : list of weight information\n",
    "    tau : precision at each location\n",
    "    \"\"\"\n",
    "    def __init__(self, w, a, tau, *args, **kwargs):\n",
    "        super(CAR, self).__init__(*args, **kwargs)\n",
    "        self.a = a = tt.as_tensor_variable(a)\n",
    "        self.w = w = tt.as_tensor_variable(w)\n",
    "        self.tau = tau*tt.sum(w, axis=1)\n",
    "        self.mode = 0.\n",
    "\n",
    "    def get_mu(self, x):\n",
    "\n",
    "        def weigth_mu(w, a):\n",
    "            a1 = tt.cast(a, 'int32')\n",
    "            return tt.sum(w*x[a1])/tt.sum(w)\n",
    "\n",
    "        mu_w, _ = scan(fn=weigth_mu,\n",
    "                       sequences=[self.w, self.a])\n",
    "\n",
    "        return mu_w\n",
    "\n",
    "    def logp(self, x):\n",
    "        mu_w = self.get_mu(x)\n",
    "        tau = self.tau\n",
    "        return tt.sum(continuous.Normal.dist(mu=mu_w, tau=tau).logp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
